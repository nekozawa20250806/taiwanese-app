import streamlit as st
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Alignment, Font
from openpyxl.utils import get_column_letter
import io
import json
import openai
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

st.title("å°æ¹¾è¯èªæ–‡ç« è§£æãƒ„ãƒ¼ãƒ«ï¼ˆExcel & CSVå‡ºåŠ›ï¼‰")

# ãƒ¢ãƒ‡ãƒ«é¸æŠUI
model_choice = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", ["GPT-4", "GPT-3.5"], index=0)
if model_choice == "GPT-4":
    model_name = "gpt-4"
else:
    model_name = "gpt-3.5-turbo"

st.markdown("### å°æ¹¾è¯èªã®æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ1è¡Œ1æ–‡ï¼‰ï¼š")
input_text = st.text_area("æ–‡ç« å…¥åŠ›", height=200, placeholder="éš¨è‘—åœ‹å®¶ç¶“æ¿Ÿç™¼å±•è‡³ä¸€å®šç¨‹åº¦...")

if st.button("è§£æã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"):
    if not input_text.strip():
        st.warning("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        sentences = input_text.strip().split("\n")

        sentences_data = []
        glossary_data = []

        st.info(f"{model_choice} ã§è§£æä¸­...ï¼ˆ{len(sentences)} æ–‡ï¼‰")

        for sentence in sentences:
            prompt = f"""
ä»¥ä¸‹ã®å°æ¹¾è¯èªã®æ–‡ç« ã‚’è§£æã—ã€JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚

æ–‡ç« : {sentence}

å‡ºåŠ›å½¢å¼ï¼š
{{
"japanese": "è‡ªç„¶ãªæ—¥æœ¬èªè¨³ï¼ˆè¦ç‚¹è£œè¶³ä»˜ãï¼‰",
"pinyin": "å£°èª¿è¨˜å·ä»˜ããƒ”ãƒ³ã‚¤ãƒ³",
"glossary": [
  {{"term": "å°æ¹¾è¯èªå˜èª", "meaning": "æ—¥æœ¬èªã®æ„å‘³", "pinyin": "å£°èª¿è¨˜å·ä»˜ã"}}
]
}}
"""
            try:
                response = openai.ChatCompletion.create(
                    model=model_name,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
                result = response.choices[0].message["content"]
                parsed = json.loads(result)

                sentences_data.append([sentence, parsed["japanese"], parsed["pinyin"]])
                for g in parsed["glossary"]:
                    glossary_data.append([g["term"], g["meaning"], g["pinyin"]])

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.stop()

        df_sentences = pd.DataFrame(sentences_data, columns=["å°æ¹¾è¯èª", "æ—¥æœ¬èªè¨³", "ãƒ”ãƒ³ã‚¤ãƒ³"])
        df_glossary = pd.DataFrame(glossary_data, columns=["å°æ¹¾è¯èª", "æ—¥æœ¬èªè¨³", "ãƒ”ãƒ³ã‚¤ãƒ³"])

        # Excelä½œæˆ
        excel_buffer = io.BytesIO()
        wb = Workbook()
        ws1 = wb.active
        ws1.title = "æ–‡ç« "
        ws1.append(["å°æ¹¾è¯èª", "æ—¥æœ¬èªè¨³", "ãƒ”ãƒ³ã‚¤ãƒ³"])
        for r in df_sentences.itertuples(index=False):
            ws1.append(r)

        ws2 = wb.create_sheet("èªé‡ˆ")
        ws2.append(["å°æ¹¾è¯èª", "æ—¥æœ¬èªè¨³", "ãƒ”ãƒ³ã‚¤ãƒ³"])
        for r in df_glossary.itertuples(index=False):
            ws2.append(r)

        for ws in [ws1, ws2]:
            ws.freeze_panes = "A2"
            for col in range(1, 4):
                ws.column_dimensions[get_column_letter(col)].width = 50
            for row in ws.iter_rows():
                max_height = 18
                for cell in row:
                    cell.alignment = Alignment(wrap_text=True, vertical="top")
                    cell.font = Font(name="Noto Sans CJK JP Medium", size=11)
                    if cell.value:
                        lines = str(cell.value).count("\n") + 1
                        est_lines = max(lines, len(str(cell.value)) // 50 + 1)
                        height = est_lines * 18
                        if height > max_height:
                            max_height = height
                ws.row_dimensions[row[0].row].height = max_height

        wb.save(excel_buffer)
        excel_buffer.seek(0)

        csv_sent = df_sentences.to_csv(index=False, encoding="utf-8-sig")
        csv_gloss = df_glossary.to_csv(index=False, encoding="utf-8-sig")

        st.success("ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†ï¼ä»¥ä¸‹ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼š")
        st.download_button("ğŸ“¥ Excelãƒ•ã‚¡ã‚¤ãƒ«", excel_buffer, file_name="taiwanese_analysis.xlsx")
        st.download_button("ğŸ“¥ æ–‡ç« CSV", csv_sent, file_name="taiwanese_sentences.csv")
        st.download_button("ğŸ“¥ èªé‡ˆCSV", csv_gloss, file_name="taiwanese_glossary.csv")
